{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Modules\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function reads in all images in catsfolder/ and dogsfolder/. \n",
    "#Each 64 x 64 image is reshaped into a length-4096 row vector. \n",
    "#These row vectors are stacked on top of one another to get two data\n",
    "#matrices, each with 4096 columns. The first matrix cats consists of all\n",
    "#the cat images as row vectors and the second matrix dogs consists of all\n",
    "#the dog images as row vectors.\n",
    "\n",
    "def read_cats_dogs():\n",
    "    \n",
    "    # get image filenames\n",
    "    cat_locs = glob.glob('catsfolder/*.jpg')\n",
    "    dog_locs = glob.glob('dogsfolder/*.jpg')\n",
    "    num_cats = len(cat_locs)\n",
    "    num_dogs = len(dog_locs)\n",
    "    \n",
    "    # initialize empty arrays\n",
    "    cats = np.zeros((num_cats,64*64))\n",
    "    dogs = np.zeros((num_dogs,64*64))\n",
    "              \n",
    "    #reshape images into row vectors and stack into a matrix \n",
    "    for i in range(num_cats):\n",
    "        img = cat_locs[i]\n",
    "        im = io.imread(img)\n",
    "        im = im.reshape(64*64)\n",
    "        cats[i,:] = im\n",
    "\n",
    "    for i in range(num_dogs):\n",
    "        img = dog_locs[i]\n",
    "        im = io.imread(img)\n",
    "        im = im.reshape(64*64)\n",
    "        dogs[i,:] = im\n",
    "\n",
    "    return cats, dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in an n x 4096 data matrix X and an index i. It extracts\n",
    "#the ith row of X and displays it as a grayscale 64 x 64 image.\n",
    "\n",
    "def show_image(X, i):\n",
    "    #select image\n",
    "    image = X[i,:]\n",
    "    #reshape make into a square\n",
    "    image = image.reshape((64,64))\n",
    "    #display the image\n",
    "    plt.imshow(image,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into numfolds equal-sized segments\n",
    "numfolds = 5 \n",
    "#All but one fold used for training\n",
    "trainfraction = (numfolds-1)/numfolds \n",
    "#Dimensions to try for PCA dimensionality reduction\n",
    "kvalues = np.array([10, 25, 50, 100, 250, 500])\n",
    "numkvalues = kvalues.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize arrays to store error rate estimates.\n",
    "train_error_LDA = np.zeros((numfolds,numkvalues))\n",
    "test_error_LDA = np.zeros((numfolds,numkvalues))\n",
    "train_error_QDA = np.zeros((numfolds,numkvalues))\n",
    "test_error_QDA = np.zeros((numfolds,numkvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in pet classificaton data \n",
    "dataset0,dataset1 = read_cats_dogs()\n",
    "#To speed up the script, load the cats and dogs dataset once, then\n",
    "#comment out the line above while running the rest as you refine your code.\n",
    "#Don't forget to uncomment the read_cats_dogs line if you restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine size of datasets.\n",
    "n0,d0 = dataset0.shape\n",
    "n1,d1 = dataset1.shape\n",
    "n = n0 + n1\n",
    "if (d0 == d1):\n",
    "    d = d0\n",
    "else:\n",
    "    raise Exception(\"dataset0 and dataset1 do not have the same number of columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data matrix and label vector.\n",
    "datamatrix = np.vstack((dataset0,dataset1))\n",
    "labelvector = np.concatenate((np.zeros(n0),np.ones(n1)))\n",
    "#Randomly permute dataset. As a result, the probability of error\n",
    "#will change with each run of the whole script.\n",
    "permutation = np.random.permutation(n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(yguess,ytrue):\n",
    "    if (yguess.shape == ytrue.shape):\n",
    "        numguesses = yguess.size\n",
    "    else:\n",
    "        raise Exception(\"yguess and ytrue are not the same shape.\")\n",
    "    error_rate_value = 1/numguesses*np.sum(yguess != ytrue)\n",
    "    return error_rate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data matrix X, corresponding vector \n",
    "#of labels Y, and a desired label. It outputs the the number \n",
    "#of samples with desiredlabel as n_label as well as the sample\n",
    "#mean vector mu_label and sample covariance matrix sigma_label\n",
    "#for the data in X whose labels in Y are equal to desired label.\n",
    "def labeled_mean_cov(X,Y,desiredlabel):\n",
    "    \n",
    "    \n",
    "    return n_label, mu_label, sigma_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data matrix Xrun, mean vector mu, \n",
    "#eigenvector matrix V, and eigenvalues D, and dimension k. \n",
    "#It selects the k eigenvectors corresponding to the k largest\n",
    "#eigenvalues, centers the data by subtracting mu, and projects\n",
    "#the centered data to k dimensions by multiplying by the matrix\n",
    "#of k eigenvectors.\n",
    "def dimensionality_reduction(Xrun,mu,V,D,k):\n",
    "    \n",
    "    \n",
    "    return Xrun_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data matrix Xrun, a training data matrix Xtrain,\n",
    "#and a training label vector ytrain.  It produces a column vector guesses,\n",
    "#correspoding to the nearest neighbor classifier for each row of the data\n",
    "#matrix Xrun.\n",
    "\n",
    "def nearest_neighbor(Xrun,Xtrain,ytrain):\n",
    "    \n",
    "\n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data matrix Xrun as well the mean vectors mu0, mu1 \n",
    "#and the covariance matrices sigma0, sigma1 estimated from the training data\n",
    "#and produces a vector guesses, corresponding to the ML rule for Gaussian vectors\n",
    "#with different means and the same covariance matrix, which is referred to as \n",
    "#Linear Discriminant Analysis (LDA) in machine learning.\n",
    "def LDA(Xrun,mu0,mu1,sigmapooled):\n",
    "    \n",
    "    \n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data matrix Xrun as well the mean vectors mu0, mu1 \n",
    "#and the covariance matrices sigma0, sigma1 estimated from the training data\n",
    "#and produces a vector guesses, corresponding to the ML rule for Gaussian vectors\n",
    "#with different means and different covariance matrices, which is referred to as \n",
    "#Quadratic Discriminant Analysis (QDA) in machine learning.\n",
    "def QDA(Xrun,mu0,mu1,sigma0,sigma1):\n",
    "    \n",
    "    \n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over folds, using the mth fold for testing, remainder for training.\n",
    "for m in range(numfolds):\n",
    "    print(\"Fold \" + str(m+1) + \" out of \" + str(numfolds) + \".\")\n",
    "    permshift = np.roll(permutation,math.floor(n*m/numfolds))\n",
    "    dataperm = datamatrix[permshift,:]\n",
    "    labelperm = labelvector[permshift]\n",
    "    #Split dataset into training and test data.\n",
    "    Xtrain = dataperm[0:math.floor(n*trainfraction),:]\n",
    "    Xtest = dataperm[math.floor(n*trainfraction):,:]\n",
    "    Ytrain = labelperm[0:math.floor(n*trainfraction)]\n",
    "    Ytest = labelperm[math.floor(n*trainfraction):]\n",
    "    ntrain = Xtrain.shape[0]\n",
    "    ntest = Xtest.shape[0]\n",
    "    \n",
    "    #Estimate mean vector and covariance matrix from Xtrain.\n",
    "    mu = np.mean(Xtrain, axis=0)\n",
    "    sigma = np.cov(Xtrain, rowvar=False)\n",
    "    #Determine eigenvalues and eigenvectors.\n",
    "    D, V = np.linalg.eigh(sigma) \n",
    "    #Loop over different sizes of dimension k for dimensionality reduction\n",
    "    for j in range(numkvalues):\n",
    "        k = kvalues[j] #Dimensionality reduction parameter.\n",
    "        print(\"Trying dimension \"+ str(k) + \".\")\n",
    "        #Reduce training and testing data to k dimensions.\n",
    "        Xtrain_reduced = dimensionality_reduction(Xtrain,mu,V,D,k)\n",
    "        Xtest_reduced = dimensionality_reduction(Xtest,mu,V,D,k)\n",
    "\n",
    "        #Determine number of samples, mean vector, \n",
    "        #and covariance matrix for each label.\n",
    "        n0train,mu0,sigma0 = labeled_mean_cov(Xtrain_reduced,Ytrain,0)\n",
    "        n1train,mu1,sigma1 = labeled_mean_cov(Xtrain_reduced,Ytrain,1) \n",
    "\n",
    "        #Using the NearestNeighbor classifier, produce guesses for the\n",
    "        # training and testing data.\n",
    "\n",
    "        trainguesses_NN   = nearest_neighbor(Xtrain_reduced,Xtrain_reduced,Ytrain)\n",
    "        testguesses_NN   = nearest_neighbor(Xtest_reduced,Xtrain_reduced,Ytrain)\n",
    "\n",
    "         #Store resulting NN error rates.\n",
    "        train_error_NN[m,j] = error_rate(trainguesses_NN,Ytrain)\n",
    "        test_error_NN[m,j] = error_rate(testguesses_NN,Ytest)\n",
    "\n",
    "        \n",
    "        #Using the LDA algorithm (which is equivalent to modeling the data\n",
    "        #as Gaussian with different mean vectors and the same covariance\n",
    "        #matrix), produce guesses for the training and testing data.\n",
    "        sigmapooled = 1/(n0train+n1train-2)*((n0train-1)*sigma0+(n1train-1)*sigma1)\n",
    "        trainguesses_LDA = LDA(Xtrain_reduced,mu0,mu1,sigmapooled)\n",
    "        testguesses_LDA = LDA(Xtest_reduced,mu0,mu1,sigmapooled)\n",
    "        \n",
    "        #Store resulting LDA error rates.\n",
    "        train_error_LDA[m,j] = error_rate(trainguesses_LDA,Ytrain)\n",
    "        test_error_LDA[m,j] = error_rate(testguesses_LDA,Ytest)\n",
    "        \n",
    "        #Using the QDA algorithm (which is equivalent to modeling the data\n",
    "        #as Gaussian with different mean vectors and different covariance\n",
    "        #matrices), produce guesses for the training and testing data.\n",
    "        trainguesses_QDA = QDA(Xtrain_reduced,mu0,mu1,sigma0,sigma1)\n",
    "        testguesses_QDA = QDA(Xtest_reduced,mu0,mu1,sigma0,sigma1)\n",
    "        \n",
    "        #Store resulting QDA error rates.\n",
    "        train_error_QDA[m,j] = error_rate(trainguesses_QDA,Ytrain)\n",
    "        test_error_QDA[m,j] = error_rate(testguesses_QDA,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine average error rates over folds.\n",
    "avg_train_error_NN = np.mean(train_error_NN,axis=0)\n",
    "avg_test_error_NN = np.mean(test_error_NN,axis=0)\n",
    "avg_train_error_LDA = np.mean(train_error_LDA,axis=0)\n",
    "avg_test_error_LDA = np.mean(test_error_LDA,axis=0)\n",
    "avg_train_error_QDA = np.mean(train_error_QDA,axis=0)\n",
    "avg_test_error_QDA = np.mean(test_error_QDA,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average error rates. \n",
    "fig = plt.figure()\n",
    "plt.plot(kvalues,avg_train_error_NN,marker=\"o\",color=\"magenta\")\n",
    "plt.plot(kvalues,avg_test_error_NN,marker=\"x\",color=\"magenta\")\n",
    "plt.plot(kvalues,avg_train_error_LDA,marker=\"o\",color=\"red\")\n",
    "plt.plot(kvalues,avg_test_error_LDA,marker=\"x\",color=\"red\")\n",
    "plt.plot(kvalues,avg_train_error_QDA,marker=\"o\",color=\"blue\")\n",
    "plt.plot(kvalues,avg_test_error_QDA,marker=\"x\",color=\"blue\")\n",
    "plt.xlabel('Dimension k')\n",
    "plt.ylabel('Average Error Rate')\n",
    "plt.legend(['LDA Training Error','LDA Testing Error','QDA Training Error','QDA Testing Error'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
